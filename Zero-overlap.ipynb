{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf3cf9b-2362-47d6-b313-f58efd382c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jitting Chamfer 3D\n",
      "Loaded JIT 3D CUDA chamfer distance\n",
      "Loaded JIT 3D CUDA emd\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Warning: Open3D was built with CUDA 11.6 butPyTorch was built with CUDA 11.7. Falling back to CPU for now.Otherwise, install PyTorch with CUDA 11.6.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "path = os.path.abspath(\"/home/jovyan/RobustPCR/Zero-overlap-test/SVDFormer\")\n",
    "sys.path.append(path)\n",
    "\n",
    "import torch\n",
    "from config_55 import cfg\n",
    "from models.SVDFormer import Model\n",
    "import utils.data_loaders\n",
    "import utils.helpers\n",
    "from utils.average_meter import AverageMeter\n",
    "from utils.loss_utils import *\n",
    "from models.model_utils import PCViews\n",
    "from models.model_utils import fps_subsample\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchgeometry as tgm\n",
    "import open3d.ml.torch as ml3d\n",
    "\n",
    "os.chdir(\"/home/jovyan/RobustPCR/Zero-overlap-test/gedi\")\n",
    "from backbones.pointnet2_ops_lib.pointnet2_ops.pointnet2_modules import PointnetSAModule\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# path = os.path.abspath(\"/home/jovyan/RobustPCR/Zero-overlap-test/gedi\")\n",
    "# sys.path.append(path)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cfg.CONST.DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cabe846-d480-42d3-9a16-78616a3aaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud_1(data1, name, idx, color = 'greens'):\n",
    "    data1 = pd.DataFrame({'x1': data1[...,0],\n",
    "                         'y1': data1[...,1],\n",
    "                         'z1': data1[...,2],})\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=data1['x1'], y=data1['y1'], z=data1['z1'], \n",
    "                     mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data1['z1'],                # set color to an array/list of desired values\n",
    "            colorscale=color,   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    fig.write_html(\"/home/jovyan/RobustPCR/Zero-overlap-test/exp_out/\" + idx + '_' + name +  \".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4bb1a0-740a-4599-892e-f6784f42d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud_2(data1, data2, name, idx, color1 = 'reds', color2 = 'blues',):\n",
    "    \n",
    "    data1 = pd.DataFrame({'x1': data1[...,0],\n",
    "                         'y1': data1[...,1],\n",
    "                         'z1': data1[...,2],})\n",
    "\n",
    "    data2 = pd.DataFrame({'x2': data2[...,0],\n",
    "                          'y2': data2[...,1],\n",
    "                          'z2': data2[...,2],})\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=data1['x1'], y=data1['y1'], z=data1['z1'], \n",
    "                     mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data1['z1'],                # set color to an array/list of desired values\n",
    "            colorscale=color1,   # choose a colorscale\n",
    "            opacity=0.2\n",
    "        )),\n",
    "        go.Scatter3d(x=data2['x2'], y=data2['y2'], z=data2['z2'],\n",
    "                    mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data2['z2'],                # set color to an array/list of desired values\n",
    "            colorscale=color2,   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    fig.write_html(\"/home/jovyan/RobustPCR/Zero-overlap-test/exp_out/\" + idx + '_' + name  + \".html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad52c4a-d233-49dc-872b-e91c756f732b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dump_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def process(subset):\n",
    "    with open(f'modelnet40_ply_hdf5_2048/{subset}_files.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    all_points = []\n",
    "    all_normals = []\n",
    "    all_labels = []\n",
    "    for line in lines:\n",
    "        filename = line.strip()\n",
    "        print(filename.split(\"/\")[-1])\n",
    "        h5file = h5py.File(f'modelnet40_ply_hdf5_2048/{filename.split(\"/\")[-1]}', 'r')\n",
    "        all_points.append(h5file['data'][:])\n",
    "        all_normals.append(h5file['normal'][:])\n",
    "        all_labels.append(h5file['label'][:].flatten().astype(np.int))\n",
    "    points = np.concatenate(all_points, axis=0)\n",
    "    normals = np.concatenate(all_normals, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "    print(f'{subset} data loaded.')\n",
    "    all_data = []\n",
    "    num_data = points.shape[0]\n",
    "    for i in range(num_data):\n",
    "        all_data.append(dict(points=points[i], normals=normals[i], label=labels[i]))\n",
    "    if subset == 'train':\n",
    "        indices = np.random.permutation(num_data)\n",
    "        num_train = int(num_data * 0.8)\n",
    "        num_val = num_data - num_train\n",
    "        train_indices = indices[:num_train]\n",
    "        val_indices = indices[num_train:]\n",
    "        train_data = [all_data[i] for i in train_indices.tolist()]\n",
    "        dump_pickle(train_data, 'train.pkl')\n",
    "        val_data = [all_data[i] for i in val_indices.tolist()]\n",
    "        dump_pickle(val_data, 'val.pkl')\n",
    "    else:\n",
    "        dump_pickle(all_data, 'test.pkl')\n",
    "        \n",
    "def random_sample_plane():\n",
    "    r\"\"\"Random sample a plane passing the origin and return its normal.\"\"\"\n",
    "    phi = np.random.uniform(0.0, 2 * np.pi)  # longitude\n",
    "    theta = np.random.uniform(0.0, np.pi)  # latitude\n",
    "\n",
    "    x = np.sin(theta) * np.cos(phi)\n",
    "    y = np.sin(theta) * np.sin(phi)\n",
    "    z = np.cos(theta)\n",
    "    normal = np.asarray([x, y, z])\n",
    "\n",
    "    return normal\n",
    "\n",
    "def random_crop_point_cloud_with_plane(points, p_normal=None, keep_ratio=0.7, normals=None):\n",
    "    \"\"\"Random crop a point cloud with a plane and keep num_samples points.\"\"\"\n",
    "    num_samples = int(np.floor(points.shape[0] * keep_ratio + 0.5))\n",
    "    if p_normal is None:\n",
    "        p_normal = random_sample_plane()  # (3,)\n",
    "    distances = np.dot(points, p_normal)\n",
    "    sel_indices = np.argsort(-distances)[:num_samples]  # select the largest K points\n",
    "    remain_indices = [i for i in range(num_samples) if i not in sel_indices]\n",
    "    points_1 = points[sel_indices]\n",
    "    \n",
    "    points_2 = points[remain_indices]\n",
    "\n",
    "    if normals is not None:\n",
    "        normals = normals[sel_indices]\n",
    "        return points_1, points_2, normals\n",
    "    else:\n",
    "        return points_1, points_2\n",
    "    \n",
    "def use_o3d(pts, name, write_text=True):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "    # the method Vector3dVector() will convert numpy array of shape (n, 3) to Open3D format.\n",
    "    # see http://www.open3d.org/docs/release/python_api/open3d.utility.Vector3dVector_.html#open3d.utility.Vector3dVector\n",
    "    #print('pts', pts.shape)\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "\n",
    "    # http://www.open3d.org/docs/release/python_api/open3d.io.write_point_cloud_.html#open3d.io.write_point_cloud\n",
    "    o3d.io.write_point_cloud(\"%s.ply\" % name, pcd, write_ascii=write_text)\n",
    "\n",
    "    # read ply file\n",
    "    # pcd = o3d.io.read_point_cloud('%s.ply' % name)\n",
    "\n",
    "\n",
    "class tnet(nn.Module):\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(tnet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(3, 256, 1, bias=False),\n",
    "                                   nn.BatchNorm1d(256),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(256, 512, 1, bias=False),\n",
    "                                   nn.BatchNorm1d(512),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(512, 1024, 1, bias=False),\n",
    "                                   nn.BatchNorm1d(1024))\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(1024, 512, bias=False),\n",
    "                                 nn.BatchNorm1d(512),\n",
    "                                 nn.ReLU())\n",
    "\n",
    "        self.fc2 = nn.Sequential(nn.Linear(512, 256, bias=False),\n",
    "                                 nn.BatchNorm1d(256),\n",
    "                                 nn.ReLU())\n",
    "        self._init_last_layer()\n",
    "\n",
    "    def _init_last_layer(self):\n",
    "        self.fc3 = nn.Linear(256, 9, bias=True)\n",
    "        torch.nn.init.zeros_(self.fc3.bias)\n",
    "\n",
    "    def _forward_last_layer(self, x):\n",
    "        x = self.fc3(x)\n",
    "        x = x + torch.eye(3, device='cuda').view(1, 9).repeat(x.size()[0], 1)\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, x.shape[1])\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self._forward_last_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class qnet(tnet):\n",
    "\n",
    "    def _init_last_layer(self):\n",
    "        self.fc3 = nn.Linear(256, 4, bias=True)\n",
    "        torch.nn.init.zeros_(self.fc3.bias)\n",
    "\n",
    "    def _forward_last_layer(self, x):\n",
    "        quat = self.fc3(x)\n",
    "        quat = quat + torch.tensor([1, 0, 0, 0], device='cuda').repeat(quat.size()[0], 1)\n",
    "        quat = F.normalize(quat, p=2, dim=1)\n",
    "        return quat\n",
    "\n",
    "\n",
    "class PointNet2Feature(nn.Module):\n",
    "\n",
    "    def __init__(self, dim=32):\n",
    "        super(PointNet2Feature, self).__init__()\n",
    "\n",
    "        self.use_xyz = True\n",
    "        self.qnet = qnet()\n",
    "\n",
    "        self.samodule1 = PointnetSAModule(\n",
    "            npoint=128,\n",
    "            radius=0.2,\n",
    "            nsample=32,\n",
    "            mlp=[3, 128, 128, 128],\n",
    "            use_xyz=self.use_xyz,\n",
    "        )\n",
    "\n",
    "        self.samodule2 = PointnetSAModule(\n",
    "            npoint=64,\n",
    "            radius=0.4,\n",
    "            nsample=16,\n",
    "            mlp=[128+3, 256, 256, 256],\n",
    "            use_xyz=self.use_xyz,\n",
    "        )\n",
    "\n",
    "        self.samodule3 = PointnetSAModule(\n",
    "            mlp=[256+3, 512, 512, 1024], use_xyz=self.use_xyz\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 512, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, dim),\n",
    "        )\n",
    "\n",
    "    def _forward(self, pc):\n",
    "\n",
    "        quat = self.qnet(pc)\n",
    "        angle_axis = tgm.quaternion_to_angle_axis(quat)\n",
    "        _trans = tgm.angle_axis_to_rotation_matrix(angle_axis)\n",
    "        trans = _trans[:, :3, :3]\n",
    "        pc = trans @ pc\n",
    "\n",
    "        xyz = pc.transpose(1, 2).contiguous()\n",
    "        xyz, features = self.samodule1(xyz, None)\n",
    "        xyz, features = self.samodule2(xyz, features)\n",
    "        xyz, features = self.samodule3(xyz, features)\n",
    "        out = self.fc_layer(features.squeeze(-1))\n",
    "        out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "        return out, pc, trans\n",
    "\n",
    "    def forward(self, xa, xp=torch.Tensor([])):\n",
    "        if xp.nelement() == 0:\n",
    "            f, _, _ = self._forward(xa)\n",
    "            return f\n",
    "        else:\n",
    "            f0, pc0, trans0 = self._forward(xa)\n",
    "            f1, pc1, trans1 = self._forward(xp)\n",
    "            return f0, pc0, trans0, f1, pc1, trans1\n",
    "\n",
    "\n",
    "class LRF(nn.Module):\n",
    "\n",
    "    def __init__(self, patches_per_pair=256, samples_per_patch=256, eps=1e-12, r_lrf=1, device='cpu'):\n",
    "        super(LRF, self).__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.r_lrf = r_lrf\n",
    "        self.patches_per_pair = patches_per_pair\n",
    "        self.samples_per_patch = samples_per_patch\n",
    "        self.device = device\n",
    "\n",
    "    def _forward(self, xp, xpi):\n",
    "\n",
    "        B, N, c = xpi.size()\n",
    "        xpi = xpi.contiguous()  # dim = B x 3 x N\n",
    "        xp = xp.unsqueeze(2).contiguous()  # dim = B x 3 x 1\n",
    "\n",
    "        # zp\n",
    "        x = xp - xpi  # pi->p = p - pi\n",
    "        xxt = torch.bmm(x, x.transpose(1, 2)) / c\n",
    "\n",
    "        _, _, v = torch.svd(xxt.to(self.device))\n",
    "        v = v.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sum_ = (v[..., -1].unsqueeze(1) @ x).sum(2)\n",
    "            _sign = torch.ones((len(xpi), 1), device=self.device) - 2 * (sum_ < 0)\n",
    "\n",
    "        zp = (_sign * v[..., -1]).unsqueeze(1)  # B x 1 x 3\n",
    "\n",
    "        # xp\n",
    "        x *= -1  # p->pi = pi - p\n",
    "        norm = (zp @ x).transpose(1, 2)\n",
    "        proj = norm * zp\n",
    "\n",
    "        vi = x - proj.transpose(1, 2)\n",
    "\n",
    "        x_l2 = torch.sqrt((x ** 2).sum(dim=1, keepdim=True))\n",
    "\n",
    "        alpha = self.r_lrf - x_l2\n",
    "        alpha = alpha * alpha\n",
    "        beta = (norm * norm).transpose(1, 2)\n",
    "        vi_c = (alpha * beta * vi).sum(2)\n",
    "\n",
    "        xp = (vi_c / torch.sqrt((vi_c ** 2).sum(1, keepdim=True)))\n",
    "\n",
    "        # yp\n",
    "        yp = torch.cross(xp, zp.squeeze(), dim=1)\n",
    "\n",
    "        lrf = torch.cat((xp.unsqueeze(2), yp.unsqueeze(2), zp.transpose(1, 2)), dim=2)\n",
    "\n",
    "        return lrf\n",
    "\n",
    "    def forward(self, x0, x0i, x1=None, x1i=None):\n",
    "\n",
    "        # compute local reference frames\n",
    "        lrf0 = self._forward(x0, x0i)\n",
    "        inds = np.random.choice(x0i.shape[2], self.samples_per_patch, replace=False)\n",
    "        _out_x0 = (x0i[..., inds] - x0.unsqueeze(-1)) / self.r_lrf\n",
    "        out_x0 = lrf0.transpose(1, 2) @ _out_x0\n",
    "\n",
    "        if x1 is None:\n",
    "            return out_x0\n",
    "\n",
    "        lrf1 = self._forward(x1, x1i)\n",
    "        inds = np.random.choice(x1i.shape[2], self.samples_per_patch, replace=False)\n",
    "        _out_x1 = (x1i[..., inds] - x1.unsqueeze(-1)) / self.r_lrf\n",
    "        out_x1 = lrf1.transpose(1, 2) @ _out_x1\n",
    "\n",
    "        return out_x0, out_x1\n",
    "\n",
    "\n",
    "class GeDi:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.dim = config['dim']\n",
    "        self.samples_per_batch = config['samples_per_batch']\n",
    "        self.samples_per_patch_lrf = config['samples_per_patch_lrf']\n",
    "        self.samples_per_patch_out = config['samples_per_patch_out']\n",
    "        self.r_lrf = config['r_lrf']\n",
    "\n",
    "        self.lrf = LRF(patches_per_pair=self.samples_per_batch,\n",
    "                       samples_per_patch=self.samples_per_patch_out,\n",
    "                       r_lrf=self.r_lrf,\n",
    "                       device='cpu')\n",
    "\n",
    "        self.gedi_net = PointNet2Feature(dim=self.dim)\n",
    "        self.gedi_net.load_state_dict(torch.load(config['fchkpt_gedi_net'])['pnet_model_state_dict'])\n",
    "        self.gedi_net.cuda().eval()\n",
    "\n",
    "    def compute(self, pts, pcd):\n",
    "\n",
    "        radii = self.r_lrf * torch.ones((len(pts)))\n",
    "\n",
    "        out = ml3d.ops.radius_search(pcd, pts, radii,\n",
    "                                     points_row_splits=torch.LongTensor([0, len(pcd)]),\n",
    "                                     queries_row_splits=torch.LongTensor([0, len(pts)]))\n",
    "\n",
    "        pcd_desc = np.empty((len(pts), self.dim))\n",
    "\n",
    "        for b in range(int(np.ceil(len(pts) / self.samples_per_batch))):\n",
    "\n",
    "            i_start = b * self.samples_per_batch\n",
    "            i_end = (b + 1) * self.samples_per_batch\n",
    "            if i_end > len(pts):\n",
    "                i_end = len(pts)\n",
    "\n",
    "            x = np.empty((i_end - i_start, 3, self.samples_per_patch_lrf))\n",
    "\n",
    "            j = 0\n",
    "            for i in range(i_start, i_end):\n",
    "\n",
    "                _inds = out[0][out[1][i]:out[1][i + 1]]\n",
    "                try:\n",
    "                    inds = np.random.choice(_inds.numpy(), size=self.samples_per_patch_lrf, replace=False)\n",
    "                except:\n",
    "                    # print('[w] got patch with few points -> {}. Padding with replicas ...'.format(len(pt_nn)))\n",
    "                    inds = np.r_[_inds, np.random.choice(_inds.numpy(), self.samples_per_patch_lrf - len(_inds))]\n",
    "\n",
    "                x[j] = pcd[inds].T\n",
    "\n",
    "                j += 1\n",
    "\n",
    "            x = torch.Tensor(x)\n",
    "\n",
    "            patch = self.lrf(pts[i_start:i_end], x)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                f = self.gedi_net(patch.cuda())\n",
    "\n",
    "            pcd_desc[i_start:i_end] = f.cpu().detach().numpy()[:i_end - i_start]\n",
    "\n",
    "        return pcd_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea222a5-9e03-4141-9816-67d0ec9d5960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(xyz, data, idx):\n",
    "\n",
    "    os.chdir(\"/home/jovyan/RobustPCR/Zero-overlap-test/gedi\")\n",
    "    use_o3d(xyz, 0)\n",
    "    use_o3d(data, 2)\n",
    "    #print('xyz', xyz, 'data', data)\n",
    "\n",
    "    config = {'dim': 32,                                            # descriptor output dimension\n",
    "              'samples_per_batch': 500,                             # batches to process the data on GPU\n",
    "              'samples_per_patch_lrf': 4000,                        # num. of point to process with LRF\n",
    "              'samples_per_patch_out': 512,                         # num. of points to sample for pointnet++\n",
    "              'r_lrf': .5,                                          # LRF radius\n",
    "              'fchkpt_gedi_net': 'data/chkpts/3dmatch/chkpt.tar'}   # path to checkpoint\n",
    "\n",
    "    voxel_size = .01\n",
    "    patches_per_pair = 5000\n",
    "\n",
    "    # initialising class\n",
    "    gedi = GeDi(config=config)\n",
    "\n",
    "    # getting a pair of point clouds\n",
    "    pcd0 = o3d.io.read_point_cloud('/home/jovyan/RobustPCR/Zero-overlap-test/gedi/0.ply')\n",
    "    pcd1 = o3d.io.read_point_cloud('/home/jovyan/RobustPCR/Zero-overlap-test/gedi/2.ply')\n",
    "\n",
    "    pcd0.paint_uniform_color([1, 0.706, 0])\n",
    "    pcd1.paint_uniform_color([0, 0.651, 0.929])\n",
    "\n",
    "    # estimating normals (only for visualisation)\n",
    "    pcd0.estimate_normals()\n",
    "    pcd1.estimate_normals()\n",
    "\n",
    "    o3d.visualization.draw_geometries([pcd0, pcd1])\n",
    "\n",
    "    # randomly sampling some points from the point cloud\n",
    "    inds0 = np.random.choice(np.asarray(pcd0.points).shape[0], patches_per_pair, replace=True)\n",
    "    inds1 = np.random.choice(np.asarray(pcd1.points).shape[0], patches_per_pair, replace=True)\n",
    "\n",
    "    pts0 = torch.tensor(np.asarray(pcd0.points)[inds0]).float()\n",
    "    pts1 = torch.tensor(np.asarray(pcd1.points)[inds1]).float()\n",
    "\n",
    "    # applying voxelisation to the point cloud\n",
    "    pcd0 = pcd0.voxel_down_sample(voxel_size)\n",
    "    pcd1 = pcd1.voxel_down_sample(voxel_size)\n",
    "\n",
    "    _pcd0 = torch.tensor(np.asarray(pcd0.points)).float()\n",
    "    _pcd1 = torch.tensor(np.asarray(pcd1.points)).float()\n",
    "\n",
    "    # computing descriptors\n",
    "    pcd0_desc = gedi.compute(pts=pts0, pcd=_pcd0)\n",
    "    pcd1_desc = gedi.compute(pts=pts1, pcd=_pcd1)\n",
    "\n",
    "    # preparing format for open3d ransac\n",
    "    pcd0_dsdv = o3d.pipelines.registration.Feature()\n",
    "    pcd1_dsdv = o3d.pipelines.registration.Feature()\n",
    "\n",
    "    pcd0_dsdv.data = pcd0_desc.T\n",
    "    pcd1_dsdv.data = pcd1_desc.T\n",
    "\n",
    "    _pcd0 = o3d.geometry.PointCloud()\n",
    "    _pcd0.points = o3d.utility.Vector3dVector(pts0)\n",
    "    _pcd1 = o3d.geometry.PointCloud()\n",
    "    _pcd1.points = o3d.utility.Vector3dVector(pts1)\n",
    "\n",
    "    # applying ransac\n",
    "    est_result01 = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        _pcd0,\n",
    "        _pcd1,\n",
    "        pcd0_dsdv,\n",
    "        pcd1_dsdv,\n",
    "        mutual_filter=True,\n",
    "        max_correspondence_distance=.02,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=3,\n",
    "        checkers=[o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(.9),\n",
    "                  o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(.02)],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(50000, 1000))\n",
    "\n",
    "    # applying estimated transformation\n",
    "    pcd0.transform(est_result01.transformation)\n",
    "\n",
    "    print(est_result01)\n",
    "\n",
    "    arr0 = np.asarray(pcd0.points)\n",
    "    arr1 = np.asarray(pcd1.points)\n",
    "    \n",
    "    \n",
    "    plot_cloud_2(arr0, arr1 , 'gedi_', idx)\n",
    "    \n",
    "\n",
    "    data1 = pd.DataFrame({'x1': arr0[...,0],\n",
    "                         'y1': arr0[...,1],\n",
    "                         'z1': arr0[...,2],})\n",
    "\n",
    "    data2 = pd.DataFrame({'x2': arr1[...,0],\n",
    "                          'y2': arr1[...,1],\n",
    "                          'z2': arr1[...,2],})\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=data1['x1'], y=data1['y1'], z=data1['z1'], \n",
    "                     mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data1['z1'],                # set color to an array/list of desired values\n",
    "            colorscale='reds',   # choose a colorscale\n",
    "            opacity=0.2\n",
    "        )),\n",
    "        go.Scatter3d(x=data2['x2'], y=data2['y2'], z=data2['z2'],\n",
    "                    mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data2['z2'],                # set color to an array/list of desired values\n",
    "            colorscale='blues',   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    fig.write_html(\"/home/jovyan/RobustPCR/Zero-overlap-test/exp_out/\" + idx + \"_test1.html\")\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "                    specs=[[{'is_3d': True}, {'is_3d': True}]],\n",
    "                    )\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(x=data1['x1'], y=data1['y1'], z=data1['z1'], \n",
    "                     mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data1['z1'],                # set color to an array/list of desired values\n",
    "            colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=0.2\n",
    "        )), 1, 1)\n",
    "    fig.add_trace(go.Scatter3d(x=data2['x2'], y=data2['y2'], z=data2['z2'],\n",
    "                    mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=data2['z2'],                # set color to an array/list of desired values\n",
    "            colorscale='thermal',   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        )), 1, 2)\n",
    "    fig.update_layout()\n",
    "\n",
    "    (\"/home/jovyan/RobustPCR/Zero-overlap-test/exp_out/\" + idx + \"_test2.html\")\n",
    "    \n",
    "    \n",
    "    return est_result01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b893d09-e36e-4071-aef3-b27741a8ff4e",
   "metadata": {},
   "source": [
    "SVDFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f44c56-7729-463e-a436-075b6586576c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete collecting files of the dataset. Total files: 10518\n",
      "Start evaluating (mode: easy) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test[0/10518]  Losses = ['8.5565', '0.4734', '0.8429'] Metrics = ['8.5565', '0.4734', '0.8429']:   0%|          | 0/10518 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n",
      "RegistrationResult with fitness=2.854000e-01, inlier_rmse=1.147495e-02, and correspondence_set size of 1427\n",
      "Access transformation to get result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test[1/10518]  Losses = ['9.5995', '0.4728', '0.8633'] Metrics = ['10.6424', '0.4722', '0.8838']:   0%|          | 1/10518 [00:13<38:42:23, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n",
      "RegistrationResult with fitness=7.760000e-02, inlier_rmse=1.269448e-02, and correspondence_set size of 388\n",
      "Access transformation to get result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test[2/10518]  Losses = ['9.4655', '0.4879', '0.6965'] Metrics = ['9.1977', '0.5182', '0.3629']:   0%|          | 2/10518 [00:26<38:09:49, 13.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/jovyan/RobustPCR/Zero-overlap-test/SVDFormer\")\n",
    "\n",
    "dataset_loader = utils.data_loaders.DATASET_LOADER_MAPPING[cfg.DATASET.TEST_DATASET](cfg)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=dataset_loader.get_dataset(\n",
    "utils.data_loaders.DatasetSubset.TEST),\n",
    "                                          batch_size=1,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=utils.data_loaders.collate_fn_55,\n",
    "                                          pin_memory=True,\n",
    "                                          shuffle=False)\n",
    "\n",
    "# Setup networks and initialize networks\n",
    "model = Model(cfg)\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "checkpoint = torch.load(cfg.CONST.WEIGHTS)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# Switch models to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "n_samples = len(test_data_loader)\n",
    "test_losses = AverageMeter(['CD', 'DCD', 'F1'])\n",
    "test_metrics = AverageMeter(['CD','DCD','F1'])\n",
    "category_metrics = dict()\n",
    "mclass_metrics = AverageMeter(['CD','DCD','F1'])\n",
    "render = PCViews(TRANS=-cfg.NETWORK.view_distance, RESOLUTION=224)\n",
    "\n",
    "# Eval settings\n",
    "crop_ratio = {\n",
    "    'easy': 1 / 5,\n",
    "    'median': 1 / 2,\n",
    "    'hard': 3 / 4\n",
    "}\n",
    "choice = [torch.Tensor([1, 1, 1]), torch.Tensor([1, 1, -1]), torch.Tensor([1, -1, 1]), torch.Tensor([-1, 1, 1]),\n",
    "          torch.Tensor([-1, -1, 1]), torch.Tensor([-1, 1, -1]), torch.Tensor([1, -1, -1]),\n",
    "          torch.Tensor([-1, -1, -1])]\n",
    "\n",
    "mode = cfg.CONST.mode\n",
    "\n",
    "print('Start evaluating (mode: {:s}) ...'.format(mode))\n",
    "#_R, _T = list(), list()\n",
    "epoch_idx = -1\n",
    "test_writer=None\n",
    "metrics = collections.defaultdict(dict)\n",
    "# Testing loop\n",
    "with tqdm(test_data_loader) as t:\n",
    "    for batch_idx, (taxonomy_id, model_ids, data) in enumerate(t):\n",
    "        #print(model_ids, taxonomy_id, model_ids, data['gtcloud'].shape)\n",
    "        \n",
    "        R = Rotation.from_euler('z', [30], degrees=True).as_matrix()[0]\n",
    "        T = np.array([[0.1],[0.1],[0.1]]).T\n",
    "        \n",
    "        if batch_idx <1000:\n",
    "            taxonomy_id = taxonomy_id[0] if isinstance(taxonomy_id[0], str) else taxonomy_id[0].item()\n",
    "            with torch.no_grad():\n",
    "                for k, v in data.items():\n",
    "                    data[k] = utils.helpers.var_or_cuda(v)\n",
    "                \n",
    "                sample = data['gtcloud'] \n",
    "                #print(sample.shape)\n",
    "                plot_cloud_1(sample.cpu().numpy()[0], 'sample_', str(model_ids[0]))\n",
    "                \n",
    "                init_1, init_2 = random_crop_point_cloud_with_plane(sample.cpu().numpy()[0], keep_ratio=0.6)\n",
    "                \n",
    "                #### нужна вторая часть облака \n",
    "                \n",
    "                gt = torch.Tensor(init_1).to('cuda') @ torch.Tensor(R).to('cuda') + torch.Tensor(T).to('cuda')\n",
    "                gt = torch.unsqueeze(gt, 0)\n",
    "                _, npoints, _ = gt.size()\n",
    "                plot_cloud_2(init_1, init_2, 'points_', str(model_ids[0]))\n",
    "                plot_cloud_2(gt.cpu().numpy()[0], init_2, 'rotation_', str(model_ids[0]))\n",
    "                \n",
    "                # partial clouds from fixed viewpoints\n",
    "                #num_crop = int(npoints * crop_ratio[mode])\n",
    "                #for partial_id, item in enumerate(choice):\n",
    "                #    partial, _ = utils.helpers.seprate_point_cloud(gt, npoints, num_crop, fixed_points = item)\n",
    "                #    _partial = partial\n",
    "                    \n",
    "                partial = fps_subsample(gt, 2048)\n",
    "                #partial = partial #@ torch.Tensor(R).to('cuda') #+ torch.Tensor(T).to('cuda')\n",
    "                partial_depth = torch.unsqueeze(render.get_img(partial), 1)\n",
    "                pcds_pred = model(partial.contiguous(),partial_depth)\n",
    "                cdl1,cdl2,f1 = calc_cd(pcds_pred[-1],gt,calc_f1=True)\n",
    "                dcd,_,_ = calc_dcd(pcds_pred[-1],gt)\n",
    "\n",
    "                cd = cdl2.mean().item() * 1e3\n",
    "                dcd = dcd.mean().item()\n",
    "                f1 = f1.mean().item()\n",
    "\n",
    "                _metrics = [cd, dcd, f1]\n",
    "                test_losses.update([cd, dcd, f1])\n",
    "\n",
    "                test_metrics.update(_metrics)\n",
    "\n",
    "                t.set_description('Test[%d/%d]  Losses = %s Metrics = %s' %(batch_idx, n_samples,  ['%.4f' % l for l in test_losses.avg()\n",
    "                                                                                ], ['%.4f' % m for m in _metrics]))\n",
    "                partial_depth = partial_depth.cpu().numpy()\n",
    "                #_partial = _partial.cpu().numpy()\n",
    "                partial = partial.cpu().numpy()\n",
    "                final = pcds_pred[-1].cpu().numpy()\n",
    "                #init = data['gtcloud'].cpu().numpy()[0]\n",
    "                #final = gt\n",
    "                \n",
    "                plot_cloud_2(final[0], init_2, 'svdf_', str(model_ids[0]))\n",
    "                plot_cloud_2(final[0], partial[0], 'svdf_partial', str(model_ids[0]))\n",
    "                val = test(final[0], init_2, str(model_ids[0]))\n",
    "               \n",
    "        else:\n",
    "            break\n",
    "        _R = val.transformation[:3,:3]\n",
    "        _T = val.transformation[:3,3]\n",
    "        metrics[str(model_ids[0])]['R'] = R\n",
    "        metrics[str(model_ids[0])]['T'] = T\n",
    "        metrics[str(model_ids[0])]['_R'] = _R\n",
    "        metrics[str(model_ids[0])]['_T'] = _T\n",
    "        metrics[str(model_ids[0])]['val'] = val\n",
    "        metrics[str(model_ids[0])]['_T'] = _T\n",
    "\n",
    "        #metrics[str(model_ids[0])]['rotation_error'] = rotation_error(R, _R)\n",
    "        #metrics[str(model_ids[0])]['translation_error'] = translation_error(T, _T)\n",
    "        metrics[str(model_ids[0])]['Error_R'] = Error_R(R, _R)\n",
    "        metrics[str(model_ids[0])]['Error_t'] = Error_t(T, _T)\n",
    "                   \n",
    "                    \n",
    "    print('============================ TEST RESULTS ============================')\n",
    "    print('Taxonomy', end='\\t')\n",
    "    print('#Sample', end='\\t')\n",
    "    for metric in test_metrics.items:\n",
    "        print(metric, end='\\t')\n",
    "    print()\n",
    "    print(test_metrics.avg())\n",
    "    print('Overall', end='\\t\\t\\t')\n",
    "    for value in test_metrics.avg():\n",
    "        print(test_metrics.avg())\n",
    "        print('%.4f' % value, end='\\t')\n",
    "    print('\\n')\n",
    "\n",
    "    print('Epoch ', epoch_idx, end='\\t')\n",
    "    for value in test_losses.avg():\n",
    "        print('%.4f' % value, end='\\t')\n",
    "    print('\\n')\n",
    "\n",
    "    # Add testing results to TensorBoard\n",
    "    if test_writer is not None:\n",
    "        test_writer.add_scalar('Loss/Epoch/cd', test_losses.avg(0), epoch_idx)\n",
    "        test_writer.add_scalar('Loss/Epoch/dcd', test_losses.avg(1), epoch_idx)\n",
    "        test_writer.add_scalar('Loss/Epoch/f1', test_losses.avg(2), epoch_idx)\n",
    "        for i, metric in enumerate(test_metrics.items):\n",
    "            test_writer.add_scalar('Metric/%s' % metric, test_metrics.avg(i), epoch_idx)\n",
    "\n",
    "                    # sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca14a01-4c54-4305-9fad-1e5bcb83ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3edb1bd-d6d3-4108-b376-235ec57a88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Error_R(r1, r2):\n",
    "    '''\n",
    "    Calculate isotropic rotation degree error between r1 and r2.\n",
    "    :param r1: shape=(B, 3, 3), pred\n",
    "    :param r2: shape=(B, 3, 3), gt\n",
    "    :return:\n",
    "    '''\n",
    "    r2_inv = np.transpose(r2)#.transpose(0, 2, 1)\n",
    "    r1r2 = np.matmul(r2_inv, r1)\n",
    "    tr = r1r2[0, 0] + r1r2[1, 1] # + r1r2[:, 2, 2]\n",
    "    rads = np.arccos(np.clip((tr - 1) / 2, -1, 1))\n",
    "    degrees = rads / np.pi * 180\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd2bcfa-31a1-4284-a866-8eed18cb7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Error_t(t1, t2):\n",
    "    '''\n",
    "    calculate translation mse error.\n",
    "    :param t1: shape=(B, 3)\n",
    "    :param t2: shape=(B, 3)\n",
    "    :return:\n",
    "    '''\n",
    "    #assert t1.shape == t2.shape\n",
    "    error_t = np.sqrt(np.sum((t1 - t2) ** 2, axis=1))\n",
    "    return error_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "920d76b9-28da-4f16-9153-71ed5cfef77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_error(R1, R2):\n",
    "    \"\"\"\n",
    "    Torch batch implementation of the rotation error between the estimated and the ground truth rotatiom matrix. \n",
    "    Rotation error is defined as r_e = \\arccos(\\frac{Trace(\\mathbf{R}_{ij}^{T}\\mathbf{R}_{ij}^{\\mathrm{GT}) - 1}{2})\n",
    "\n",
    "    Args: \n",
    "        R1 (torch tensor): Estimated rotation matrices [b,3,3]\n",
    "        R2 (torch tensor): Ground truth rotation matrices [b,3,3]\n",
    "\n",
    "    Returns:\n",
    "        ae (torch tensor): Rotation error in angular degreees [b,1]\n",
    "\n",
    "    \"\"\"\n",
    "    print(R1.shape, R2.shape)\n",
    "    R1 = torch.from_numpy(R1).to('cuda')\n",
    "    R2 = torch.from_numpy(R2).to('cuda')\n",
    "    print('2', R1, R2)\n",
    "    R_ = torch.matmul(R1.transpose(0,1), R2)\n",
    "    e = torch.stack([(torch.trace(R_[_, :, :]) - 1) / 2 for _ in range(R_.shape[0])], dim=0).unsqueeze(1)\n",
    "\n",
    "    # Clamp the errors to the valid range (otherwise torch.acos() is nan)\n",
    "    e = torch.clamp(e, -1, 1, out=None)\n",
    "\n",
    "    ae = torch.acos(e)\n",
    "    pi = torch.Tensor([np.pi])\n",
    "    ae = 180. * ae / pi.to(ae.device).type(ae.dtype)\n",
    "\n",
    "    return ae\n",
    "\n",
    "\n",
    "def translation_error(t1, t2):\n",
    "    \"\"\"\n",
    "    Torch batch implementation of the rotation error between the estimated and the ground truth rotatiom matrix. \n",
    "    Rotation error is defined as r_e = \\arccos(\\frac{Trace(\\mathbf{R}_{ij}^{T}\\mathbf{R}_{ij}^{\\mathrm{GT}) - 1}{2})\n",
    "\n",
    "    Args: \n",
    "        t1 (torch tensor): Estimated translation vectors [b,3,1]\n",
    "        t2 (torch tensor): Ground truth translation vectors [b,3,1]\n",
    "\n",
    "    Returns:\n",
    "        te (torch tensor): translation error in meters [b,1]\n",
    "\n",
    "    \"\"\"\n",
    "    t1 = torch.from_numpy(t1).to('cuda')\n",
    "    t2 = torch.from_numpy(t2).to('cuda')\n",
    "    \n",
    "    return torch.norm(t1-t2, dim=(1, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
